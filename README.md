## **Project** : Mobile Agent For Smart Home Using Multimodal Learning <2023-11-13>
### **Project Field** : Multimodal Learning, Sound Classification, Image captioning, machine traslation, transformer

#### **Project Description** :
Google의 LaMDA나 유명한 OpenAI의 Chatgpt와 같은 언어 모델의 등장으로 텍스트 생성, 기계번역, 질문 응답 시스템과 같은 분야에서 각각의 모델들은 큰 기여를 해왔습니다. 그리고 Vision-Language Models과 같이 두 모달리티 사이의 상호 작용을 이해하고 활용하는 CLIP, DALL-E와 같은 모델들의 등장으로 Multimodality의 시대가 도래했다. Vision과 text뿐만 아니라 다양한 Modalities의 활용은 기존의 하나의 Modality를 가진 모델보다 풍부하고 다양한 작업을 수행할 수 있다. 이 프로젝트에서는 독거노인을 위한 위급상황 탐지가 가능한 로봇에 탑제되는 Multimodal Model을 개발하는 것을 목표로 한다. Audio classification을 통한 이진분류를 통해 Scream / Non-Scream를 통해 상황을 포착하고, Image captioning 기술을 통해 그 가족이나 응급시설에 빠르게 연락을 취할 수 있는 Model을 개발하려합니다.

### **Progress of Research** : 
1. Text Generation
2. seq2seq Model & Attention
3. Transformer (24.03.10 - 24.03.13) <br> **Attention is all you need(2017)** 논문을 읽고, Transformer Architecture Implementation practice.
4. Image Captioning
5. ViT Transformer (23.03.27 -


### **Background of Studies**
[1] P. S. Sase and S. H. Bhandari, "Human Fall Detection using Depth Videos," Department of Computer Science and Engineering, Walchand College of Engineering, Sangli, India
[2] J. Zhang and C. Zong, "Neural machine translation: Challenges, progress and future," Science China Technological Sciences, vol. 63, no. 10, pp. 2028-2050, 2020/10/01 2020, doi: 10.1007/s11431-020-1632-x.
[3] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, "Attention is all you need," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. TBD, no. TBD, pp. TBD, Jun. 2017, revised Aug. 2023. [Online]. Available: https://arxiv.org/abs/1706.03762
[4] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby, "An image is worth 16x16 words: Transformers for image recognition at scale," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. TBD, no. TBD, pp. TBD, Oct. 2020, revised Jun. 2021. [Online]. Available: https://arxiv.org/abs/2010.11929
[5] P. Xu, X. Zhu and D. A. Clifton, "Multimodal Learning With Transformers: A Survey," in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 10, pp. 12113-12132, Oct. 2023, doi: 10.1109/TPAMI.2023.3275156.
keywords: {Transformers;Task analysis;Surveys;Visualization;Taxonomy;Mathematical models;Data models;Multimodal learning;transformer;introductory;taxonomy;deep learning;machine learning},







### **출처**
1. [딥러닝 기계 번역] Transformer: Attention Is All You Need (꼼꼼한 딥러닝 논문 리뷰와 코드 실습) 동빈나

